{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EDA - CP2.ipynb","provenance":[{"file_id":"11Lzihg2vKIbo4KAIIJxW5CRZIncoWgtL","timestamp":1597302469470}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f5pR6s0kvYst","colab_type":"text"},"source":["# EDA - MAFAT challenge\n","\n","This notebook includes our EDA and conclusions regarding approaches for data augmentation and filtering later in the models.\n","\n","Keynotes:\n","\n","- **Imbalanced data**, for the training set - target tend towards the animal.\n","- **Imbalanced data**, SNR - the difference between high and low, and the number of images of target to each one of them\n","- **Geolocations** - different geolocations have a different distribution of the target.\n","- **Auxilary datasets** - each one of them has interesting data that we can use for data augmentation.\n","- Plotting spectrograms - we plotted spectrograms for:\n","  - animal vs human\n","  - HighSNR vs LowSNR\n","  - example of test spectogram and plots from the Auxilary datasets\n","\n","we noticed that for us it's difficult to distinguish between animal and human or even different SNR types. this is still in the processwe hope that a nice CNN will be able to find the pattern that we are missing"]},{"cell_type":"markdown","metadata":{"id":"p1cbXnIqwSJM","colab_type":"text"},"source":["# Vocabulary Update  \n","The project we decided to take focus on spectograms analysis. This very specific topic requires some terminology clarifications.\n","\n","* __Doppler Radar__: The type of radar used to evaluate the limb motion of the animal of human.\n","\n","\n","---\n","\n","\n","* __Spectogram__: Way of visualisation of the radar spectrum output.\n","\n","![picture](https://drive.google.com/uc?export=view&id=1j0-_Kp5azulBHvwibs7CZu29iWn-v3JA)\n","\n","\n","\n","---\n","\n","\n","\n","* __IQ data__: For now, a kind of blackbox composed of real and imaginary number. The spectograms we have to analyze are segments of 32 x 128 = Time x velocity. For each segment we have 32 * 128 = 4096 IQ values.\n","In simple words, it is the coordinates representation of the signal received by the radar\n","\n","\n","\n","---\n","\n","\n","\n","* __SNR__: Signal-to-noise ratio is a measure used in science and engineering that compares the level of a desired signal to the level of background noise.\n","> __low SNR__: More noise than desired signal  \n","> __High SNR__: More desired signal than noise\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1NBj1yCwrZpvWNOtl-D1810206WnQT7LF\" alt=\"drawing\" width=\"800\" height=\"400\"/>\n"]},{"cell_type":"markdown","metadata":{"id":"Ush533GDyoMK","colab_type":"text"},"source":["\n","###**Data Description**   \n","The data contains I/Q signals of humans or animals collected by radar sensors in different locations and times.  \n","Each signal of human or animal is a single track. The tracks in the dataset are split into 32 time-units segments.   \n","Each record in the dataset represents a single segment.\n","The goal is to classify the segments correctly.   \n","\n","A segment consists of a matrix with I/Q values and metadata. The matrix of each segment has a size of 32x128. The X-axis represents the pulse transmission time, also known as “slow-time”. The Y-axis represents the reception time of signals with respect to pulse transmission time divided into 128 equal sized bins, also known as “fast-time”. The Y-axis is usually referred to as “range” or “velocity” as wave propagation depends on the speed of light.\n","\n","For example, for Pulse Repetition Interval (PRI) of 128 ms, each Y-axis is a bin of 1 ms. For pulse sent in t(n) and a signal received in t(n+m) where   \n","0 < m <=128 the signal is set in the “m” bin of pulse n.\n","\n","* *Note: the numbers that are stated in the example above are not the real numbers and are given only for the sake of the example.*\n"]},{"cell_type":"markdown","metadata":{"id":"A7SM-tNVOlcF","colab_type":"text"},"source":["####**Data Fields** \n","8 fields describe each segment:\n","\n","  \n","\n","*   **segment_id** - The segment's unique ID. \n","*   **target_type** - What is the object detected in the segment?   \n","The possible values are: \"human\", \"animal\", \"empty\".\n","*   **snr_type** - Signal to Noise Ratio (SNR), there are 3 categories:  \n","High SNR, Low SNR, and Synthetic Low SNR. The Synthetic segments are the   \n","High SNR signals in the dataset that transformed into Low SNR artificially,   \n","will be elaborated at the end of this notebook.   \n","The possible values are: \"HighSNR\", \"LowSNR\", \"SynthSNR\".   \n","*   **track_id** - Segment is part of a continuous track. Use this identifier to locate all segments of the same track.   \n","*   **geolocation_type** - Identifies the surrounding terrain type of each location (string, categorical).   \n","*   **geolocation_id** - Each location has a unique ID (integer).   \n","*   **sensor_id** - Each Radar has a unique ID (integer). In some of the locations were number of radars.   \n","*   **date_index** - Numerical, each number represents a unique   calendar day (integer).   "]},{"cell_type":"markdown","metadata":{"id":"hjTf6q9qEPLY","colab_type":"text"},"source":["####**How the data was gathered** \n","<img src=\"https://drive.google.com/uc?export=view&id=1Fi1ok6A898pn2iuguif_-r6Rz1qk_sSX\" alt=\"drawing\" width=\"600\" height=\"400\"/>"]},{"cell_type":"markdown","metadata":{"id":"J6sJwgBkEGd-","colab_type":"text"},"source":["###**Setup**"]},{"cell_type":"code","metadata":{"id":"W8nDDW65cGsY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1599059574968,"user_tz":-180,"elapsed":1669,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}},"outputId":"01b82f21-4f81-4cdf-c225-d7d4cd045709"},"source":["%matplotlib inline\n","import os\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from termcolor import colored\n","from IPython.display import display"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"z9-fSQU7cWlI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1599059598608,"user_tz":-180,"elapsed":24879,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}},"outputId":"d4bf2dab-920d-4def-c810-5d78611ec308"},"source":["# Optional: mounting to Google Drive to read the data files.\n","from google.colab import drive\n","mount_path = '/content/gdrive'\n","drive.mount(mount_path)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k7qmclZNYeRS","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqG1lZqqRc1p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599059598609,"user_tz":-180,"elapsed":24854,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}},"outputId":"0f0b0f47-487d-454e-e0cb-d979502de5a7"},"source":["# Set and test path to competition data files\n","competition_path = 'My Drive/Final Project ITC/MAFAT Challenge/Data'\n","try:\n","  if competition_path == 'INSERT HERE':\n","    print('Please enter path to competition data files:')\n","    competition_path = input()\n","  file_path = 'MAFAT RADAR Challenge - Training Set V1.csv'\n","  with open(f'{mount_path}/{competition_path}/{file_path}') as f:\n","    f.readlines()\n","  print(colored('Everything is setup correctly', color='green'))\n","except:\n","  print(colored('Please mount drive and set competition_path correctly',\n","                color='red'))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[31mPlease mount drive and set competition_path correctly\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jnNTuyQbv5HD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599059598610,"user_tz":-180,"elapsed":24850,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def load_csv_metadata(file_path):\n","  \"\"\"\n","  Reads csv as pandas DataFrame (only Metadata).\n","\n","  Arguments:\n","    file_path -- {str} -- path to csv metadata file\n","\n","  Returns:\n","    Pandas DataFarme\n","  \"\"\"\n","  path = os.path.join(mount_path, competition_path, file_path + '.csv')\n","  with open(path, 'rb') as data:\n","    output = pd.read_csv(data)\n","  return output"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRJ9n_lKDd9I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"status":"error","timestamp":1599059599240,"user_tz":-180,"elapsed":25475,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}},"outputId":"46e5c448-6010-4f07-d2b3-923d73f237fc"},"source":["training_path = 'MAFAT RADAR Challenge - Training Set V1'\n","test_path = 'MAFAT RADAR Challenge - Public Test Set V1'\n","\n","training_set = load_csv_metadata(training_path)\n","test_set = load_csv_metadata(test_path)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-862ea4e2256e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MAFAT RADAR Challenge - Public Test Set V1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-b2279f690603>\u001b[0m in \u001b[0;36mload_csv_metadata\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \"\"\"\n\u001b[1;32m     11\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmount_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompetition_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Data/MAFAT RADAR Challenge - Training Set V1.csv'"]}]},{"cell_type":"markdown","metadata":{"id":"cB4p8613ENGB","colab_type":"text"},"source":["###**Training and Test sets Descriptives**"]},{"cell_type":"code","metadata":{"id":"HyvYNUiZDgrt","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598611,"user_tz":-180,"elapsed":24819,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["training_set.head() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HBzMoswDTc1","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598612,"user_tz":-180,"elapsed":24796,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["test_set.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCB9l9vI908w","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598613,"user_tz":-180,"elapsed":24777,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Number of obserevations (segments), and number of columns (fields)   \n","# except for the I/Q matrix and the doppler burst vector\n","\n","print(f\"The training set shape is: {training_set.shape}\")\n","print(f\"The test set shape is: {test_set.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQhyI97COY7Q","colab_type":"text"},"source":["There are 6,656 signal segments in the training set (taken from 1,510 signal tracks),   \n","and 106 segments in the public test set.\n","   \n","The segments in the test set are selected in a way that guarantees a track has at most a single segment,   \n","with the exception of very long tracks that may contribute more than one segment.    \n","The segments in the test set and the training set are not from the same tracks.   \n","Also, in the training set, all the segments of the track are available as opposed to a single segment from each track in the test set."]},{"cell_type":"code","metadata":{"id":"xYL5__VikpID","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598614,"user_tz":-180,"elapsed":24760,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# All fields in metadata are categorical, therefore only simple descriptives \n","# like the mode and the number of unique values is relevant.\n","training_set = training_set.astype(str)\n","training_set.describe().iloc[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvXqijqzHvZu","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598614,"user_tz":-180,"elapsed":24740,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["test_set = test_set.astype(str)\n","test_set.describe().iloc[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYwwyxUO8Cfw","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598615,"user_tz":-180,"elapsed":24716,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def check_missing(df):\n","  try:\n","    df.name =[x for x in globals() if globals()[x] is df][0]\n","    if sum(df.isnull().sum()) == 0:\n","      print(f\"None of the columns in {df.name} have missing data.\")\n","  except:\n","    print(df.isnull().any())\n","\n","check_missing(test_set)\n","check_missing(training_set)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W32_V93R-tD9","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598616,"user_tz":-180,"elapsed":24690,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["print(f\"The number of tracks in the training set is: {training_set['track_id'].nunique()}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-HTnIUQPru0","colab_type":"text"},"source":["There are 1,510 signal tracks split to 6,656 signal segments in the training set.  \n","We are asked to classify signal segments. Animals (0) or Humans (1)\n","The tracks and segments' SNR can be Low or High SNR.   \n","In some cases (200 Tracks) the track is in one part Low SNR and another part High SNR."]},{"cell_type":"markdown","metadata":{"id":"MPCwF-KeGUOZ","colab_type":"text"},"source":["*Tracks that have both High and Low SNR are being counted twice as two tracks    \n","(once for High SNR and once for Low SNR) but have the same track id.*\n"]},{"cell_type":"code","metadata":{"id":"9nErZAicPFjH","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598617,"user_tz":-180,"elapsed":24666,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["tracks_hsnr_and_lsnr = sum(training_set[['track_id', 'snr_type']].\n","                           groupby('track_id', as_index=False)\n","                           ['snr_type'].nunique()==2)\n","\n","tracks_one_snr = sum(training_set[['track_id', 'snr_type']].\n","                     groupby('track_id', as_index=False)\n","                     ['snr_type'].nunique()==1)\n","\n","total_count_of_tracks = training_set.groupby(['track_id', 'snr_type'], \n","                                             as_index=False).count()['track_id'].count()\n","\n","print(f'Number of tracks that are High SNR and Low SNR: {tracks_hsnr_and_lsnr}')\n","print(f'Number of tracks that are High SNR or Low SNR: {tracks_one_snr}')\n","print(f'Number of total counted tracks (grouped by snr_type and track_id): {total_count_of_tracks}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzrFKiRBUBet","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598617,"user_tz":-180,"elapsed":24648,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["print(\"\\n Bar chart - The frequency of tracks lengthes (number of segments\\\n"," in a single track) in the Training set. \\n\\n\")\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax2 = fig.add_subplot(1, 2, 2) \n","\n","segments_int_track = training_set.groupby('track_id')['segment_id'].count()\n","segments_int_track.value_counts(sort=False)[:11].plot(kind='barh', \n","                                                      figsize =(20,6),\n","                                                      ax =ax1 )\n","ax1.set_title(\"Tracks shorter than 11 segments \\n\")\n","ax1.set_ylabel('No. of segments in a single track')\n","ax1.set_xlabel('No. of tracks')\n","\n","for index, value in enumerate(segments_int_track.value_counts(sort=False)[:11]):\n","  ax1.text(value, index, str(value))\n","\n","segments_int_track = training_set.groupby('track_id')['segment_id'].count()\n","segments_int_track.value_counts(sort=False)[11:].plot(kind='barh',\n","                                                      figsize =(20,6),\n","                                                      ax =ax2 )\n","ax2.set_title(\"Tracks longer than 11 segments \\n\")\n","ax2.set_ylabel('No. of segments in a single track', labelpad =15)\n","ax2.set_xlabel('No. of tracks')\n","\n","for index, value in enumerate(segments_int_track.value_counts(sort=False)[11:]):\n","  ax2.text(value, index, str(value))\n","\n","plt.show()\n","\n","print(f\"\\n The number of segments of tracks that are shorter or equal to 11\\\n"," segments is: {segments_int_track.value_counts(sort=False)[:11].sum()}\")\n","print(f\"\\n The number of segments of tracks that are longer than 11\\\n"," segments is: {segments_int_track.value_counts(sort=False)[11:].sum()}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQ1qYPDb-X5e","colab_type":"text"},"source":["* The majority of the track have less than 11 segments.\n","* The distribution is skewed towards tracks that have few segments\n","\n","* The different segments in one single track tend to have a high correlation between each othe. This is a feature we don't want to learn because tracks in the test set have only a single segment"]},{"cell_type":"code","metadata":{"id":"8EVRjv5XQs3B","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059598618,"user_tz":-180,"elapsed":24645,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def ratio(series):\n","  \"\"\"\n","  Calculates ratios in a given series.\n","\n","  Arguments:\n","    series -- {series} -- series to calculate ratios for.\n","\n","  Returns:\n","    ratio_results -- {series} -- ratio result for each integer in the\n","                                 series array.\n","  \"\"\"\n","\n","  ratio_results = series.apply(lambda x: '{0:.1%}'.format(x/sum(series)))\n","  \n","  return ratio_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRcQVdWQO2co","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599137,"user_tz":-180,"elapsed":25142,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Bar chart - compares the number of tracks and segments by snr type in the training set.\n","\n","print(\"Training Set\")\n","fig = plt.figure()\n","\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax2 = fig.add_subplot(1, 2, 2) \n","fig.subplots_adjust(wspace=0.5)\n","\n","segments_hsnr_lsnr = training_set.groupby(\n","    ['snr_type'])['segment_id'].count()\n","tracks_hsnr_lsnr = training_set.groupby(\n","    ['snr_type'])['track_id'].nunique()\n","\n","segments_hsnr_lsnr.plot(kind='bar', figsize=(10,6), ax=ax1)\n","ax1.set_title(\"No. of segments by SNR_type \\n\")\n","ax1.set_ylabel('No. of segments', labelpad =15)\n","ax1.set_xlabel('SNR Type')\n","ax1.set_xticklabels(['High SNR','Low SNR'], rotation =0)\n","ax1.set_ylim(top=5000)\n","ax1.text(-0.13,2700,format(segments_hsnr_lsnr[0],','))\n","ax1.text(0.87,4400,format(segments_hsnr_lsnr[1],','))\n","\n","\n","tracks_hsnr_lsnr.plot(kind='bar', figsize=(10,6), ax=ax2)\n","ax2.set_title(\"No. of tracks by SNR_type \\n\")\n","ax2.set_ylabel('No. of tracks', labelpad =15)\n","ax2.set_xlabel('SNR Type')\n","ax2.set_xticklabels(['High SNR','Low SNR'], rotation =0)\n","ax2.set_ylim(top=1400)\n","ax2.text(-0.09,640,format(tracks_hsnr_lsnr[0],','))\n","ax2.text(0.87,1220,format(tracks_hsnr_lsnr[1],','))\n","\n","\n","plt.show()\n","\n","display(pd.concat([pd.DataFrame(segments_hsnr_lsnr),\n","                   pd.DataFrame(ratio(segments_hsnr_lsnr)).rename(\n","                       columns={'segment_id':'ratio'})], \n","                   axis=1).reset_index())\n","display(pd.concat([pd.DataFrame(tracks_hsnr_lsnr),\n","                   pd.DataFrame(ratio(tracks_hsnr_lsnr)).rename(\n","                       columns={'track_id':'ratio'})],\n","                   axis=1).reset_index())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPkXUtVh4_5T","colab_type":"text"},"source":["* The dataset is imbalanced. We have 1.7 times more Low SNR segments than High SNR segments. The SNR level is not the target value but it is still important to underline it. "]},{"cell_type":"code","metadata":{"id":"5I8OhI9hPOpC","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599142,"user_tz":-180,"elapsed":25125,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Bar chart - compares number of segments by snr type in the public test set.\n","print(\"Public test Set\")\n","fig = plt.figure()\n","ax1 = fig.add_subplot(1, 1, 1)\n","\n","segments_hsnr_lsnr_test = test_set.groupby(['snr_type'])['segment_id'].count()\n","segments_hsnr_lsnr_test.plot(kind='bar', figsize=(10,6), ax=ax1)\n","ax1.set_title(\"No. of segments by SNR_type in the Test set\\n\")\n","ax1.set_ylabel('No. of segments', labelpad =15)\n","ax1.set_xlabel('SNR Type')\n","ax1.set_xticklabels(['High SNR','Low SNR'], rotation =0)\n","ax1.set_ylim(top=100)\n","\n","for index, value in enumerate(segments_hsnr_lsnr_test): \n","  label = format(value, ',') \n","  ax1.annotate(label, xy=(index-0.03 , value+5), color='black')\n","    \n","plt.show()\n","\n","display(pd.concat([pd.DataFrame(segments_hsnr_lsnr_test),pd.DataFrame(\n","  ratio(segments_hsnr_lsnr_test)).rename(\n","      columns={'segment_id':'ratio'})],axis=1).reset_index())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W7mmCwABPJRe","colab_type":"text"},"source":["The ratio between HighSNR and LowSNR in the test set is more balanced than the ratio in the training set."]},{"cell_type":"markdown","metadata":{"id":"E-9p-4k61U-5","colab_type":"text"},"source":["####**Other Training Set Fields Descriptive Statistics**"]},{"cell_type":"markdown","metadata":{"id":"NQg9iT4yuphi","colab_type":"text"},"source":["Tracks and Segments frequencies by target_type and snr_type."]},{"cell_type":"code","metadata":{"id":"AYMy2yauiIsz","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599145,"user_tz":-180,"elapsed":25106,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["print(\"Training Set\")\n","target_segments = training_set.groupby(['target_type'])['segment_id'].count()\n","target_segments_hsnr_lsnr = training_set.groupby(\n","    ['target_type','snr_type'])['segment_id'].count()\n","target_tracks_hsnr_lsnr = training_set.groupby(\n","    ['target_type','snr_type'])['track_id'].nunique()\n","target_segments.plot(kind='bar', color=['tab:red','tab:blue'])\n","\n","plt.title('Target type distribution \\n')\n","plt.ylim(top=6500)\n","plt.ylabel('No. of segments')\n","plt.xlabel('Target Type')\n","plt.xticks(rotation =0)\n","plt.text(-0.08,5850,format(target_segments[0],','))\n","plt.text(0.95,970,format(target_segments[1],','))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lW7mSEZT5e66","colab_type":"text"},"source":["* Regarding the target value. The dataset is imbalanced. 6.4 more animals segments than human ones."]},{"cell_type":"code","metadata":{"id":"WczUlZPDiJMt","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599147,"user_tz":-180,"elapsed":25087,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Bar chart - compares number of segments and tracks by snr type\n","# and target type in the training set.\n","print(\"Training Set\")\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax2 = fig.add_subplot(1, 2, 2) \n","fig.subplots_adjust(wspace=0.5)\n","\n","target_segments_hsnr_lsnr.plot(kind='bar', figsize=(10,6), \n","                               color=[\n","                                      'tab:red','tab:red',\n","                                      'tab:blue','tab:blue'\n","                                      ],\n","                               label='_nolegend_',ax=ax1)\n","ax1.set_title(\"No. of segments \\n\")\n","ax1.set_ylabel('No. of segments', labelpad =15)\n","ax1.set_xlabel('Target type and SNR Type')\n","ax1.set_ylim(top=5000)\n","ax1.bar(0, target_segments_hsnr_lsnr[0], width=0.01, alpha=0.9, \n","        color='tab:red', label='Animal')\n","ax1.bar(2, target_segments_hsnr_lsnr[2], width=0.01, alpha=0.9,\n","        color='tab:blue', label='Human')\n","\n","for index, value in enumerate(target_segments_hsnr_lsnr): \n","  label = format(value, ',') \n","  ax1.annotate(label, xy=(index-0.2 , value+80), color='black')\n","\n","target_tracks_hsnr_lsnr.plot(kind='bar', figsize=(10,6), \n","                             color=['tab:red','tab:red',\n","                                    'tab:blue','tab:blue'\n","                                    ],\n","                             label='_nolegend_', ax=ax2)\n","ax2.set_title(\"No. of tracks \\n\")\n","ax2.set_ylabel('No. of tracks', labelpad =15)\n","ax2.set_xlabel('Target type and SNR Type')\n","ax2.set_ylim(top=1400)\n","\n","for index, value in enumerate(target_tracks_hsnr_lsnr): \n","  label = format(value, ',') \n","  ax2.annotate(label, xy=(index-0.2 , value+20), color='black')\n","\n","fig.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSKFh1svx5LU","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599150,"user_tz":-180,"elapsed":25072,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["target_segments_hsnr_lsnr\n","segments_display = pd.DataFrame(ratio(target_segments_hsnr_lsnr).reset_index())\n","segments_display.columns=['targe_type', 'snr_type', 'tracks_count_ratio']\n","segments_display"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Su8N7fgB6Ybb","colab_type":"text"},"source":["* The human segments are repreented in majority High SNR, whereas the animal ones are represented in majority low SNR.  \n","* Let's dive deeper into that"]},{"cell_type":"markdown","metadata":{"id":"bUUs08Ssy6bB","colab_type":"text"},"source":["##### **Crosstabulation on the Segments Frequncy - A Deeper Look**\n","The tables below are crosstabulation of segments frquency by snr_type and target_type.   \n","The Frequency can be presented in different ratios, depending on the perspective.   \n","Counting segments relative to the target type or the SNR type.   \n","\n","For example:    \n","There are 5,757 animal segments and 899 humans segments in the training set.   \n","14% of the segments are Humans and 86% are animals.   \n","37% of the segments are High SNR and 63% are Low SNR.     \n","Splitting the target type by SNR type show that most of the Low SNR segments are animals (98%).   \n","Splitting the SNR type by target type shows that 90% of Humans segments are High SNR and 10% are Low SNR.   \n","\n","See the tables below for more insights."]},{"cell_type":"code","metadata":{"id":"HN3K-266tvvf","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599152,"user_tz":-180,"elapsed":25054,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Crosstabulation tables presenting same numbers in different perspectives and ratios\n","print(\"Count segments: \\n\")\n","display(pd.crosstab(training_set['target_type'],training_set['snr_type'],\n","                    margins = True).round(2))\n","print(\"\\n Ratio by target type: \\n\")\n","display(pd.crosstab(training_set['target_type'],training_set['snr_type'],\n","                    normalize=0).round(2))\n","print(\"\\n Ratio by SNR type: \\n\")\n","display(pd.crosstab(training_set['target_type'],training_set['snr_type'],\n","                    normalize=1).round(2))\n","print(\"\\n Ratio by SNR type and target type: \\n\")\n","display(pd.crosstab(training_set['target_type'],training_set['snr_type'],\n","                    normalize='all',margins = True).round(2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gf9XA02xB3hq","colab_type":"text"},"source":["# Conclusions about SNR and target variables\n","* The train dataset is imbalanced on the variables : SNR and target value.\n","* The test dataset is not imbalanced. (We don't have acced to the target values but we know for the SNR variable)\n","* __Target__: We have 6.4 times more animals classifications than human ones\n","* __SNR__: We have 1.7 times more lowSNR data than highSNR ones\n","* Moreover, we know that High SNR is more related to humans and vice versa, low SNR is more related to animal. we should prevent the model to assume this corelation.\n","> We will have to work on making the data less imbalanced. Oversampling or undersampling are for now the mai ideas\n"]},{"cell_type":"markdown","metadata":{"id":"BqFqMsCZ67tn","colab_type":"text"},"source":["#### **Geolocations**\n","The segments in the training and the test sets are gathered from different geolocations.   \n","One of our goals it to classify well even though   \n","test segments can be from a new and unfamiliar geolocation_type or geolocation_id.   \n","In the test set there are segments from new geolocations that are not in the training set."]},{"cell_type":"markdown","metadata":{"id":"eflog0Pe8Hwm","colab_type":"text"},"source":["##### **Perfect Multicollinearity - geolocation_id**\n","The geolocation field has Multicollinearity with other fields in the training set.   \n","These relations do not necessarily exist in the auxiliary and test sets.   \n","\n","\n","1. Each geolocation id belongs to one geolocation type (This     \n","statement holds for all data sets). In each geolocation type can be   \n","one or more geolocation id.\n","2. In the training set, each geolocation id has one sensor.\n","3. In the training set, some of the date indices are unique for     specific geolocations.   \n","This means that in some calendar days only one geolocation recorded signals.   \n","4. Some of the geolocations may have only one target type.   \n","5. All geolocations have High and Low SNR segments.\n","\n","*Statements 2 and 3 are not necessarily true for geolocations in the auxiliary and test sets.*"]},{"cell_type":"code","metadata":{"id":"dIOgeWGuFIyj","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599155,"user_tz":-180,"elapsed":25033,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["print('Geolocation id, geolocation type and sensor_id: \\n')\n","display = pd.DataFrame(training_set.groupby(\n","    ['geolocation_type','geolocation_id', 'sensor_id'])['segment_id'].\n","    count())\n","display.columns=['segment_id count']\n","display.reset_index(inplace=True)\n","display"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TbBgHFb90k86","colab_type":"text"},"source":["##### **Analysis of the Distribution by target_type and geolocation_id**\n","*See tables and graphs below for an analysis of the distribution of target type and geolocation id.*"]},{"cell_type":"code","metadata":{"id":"Sp00WuhjEWow","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599158,"user_tz":-180,"elapsed":25032,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["target_geolocation_segments = training_set.groupby(\n","    ['target_type','geolocation_id'])['segment_id'].count()\n","\n","target_geolocation_id_1_and_4_hsnr_lsnr = training_set.groupby(\n","    ['target_type', 'geolocation_id','snr_type'])['segment_id'].count().\\\n","    drop(labels=[('animal', '2'), ('animal', '3')])\n","\n","target_geolocation_id_1_and_4_tracks_hsnr_lsnr = training_set.groupby(\n","    ['target_type', 'geolocation_id', 'snr_type'])['track_id'].nunique().\\\n","    drop(labels=[('animal', '2'), ('animal', '3')])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0fQfIWR-kpq","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599160,"user_tz":-180,"elapsed":25014,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["print(\"Training Set\")\n","from IPython.display import display\n","display(pd.DataFrame(target_geolocation_segments).rename(\n","    columns={'segment_id':'segment_id count'}))\n","\n","color_list=['tab:red']*4+['tab:blue']*2\n","target_geolocation_segments.plot(kind='bar', color = color_list,\n","                                 label='_nolegend_')\n","plt.bar(0, target_geolocation_segments[0], alpha=0.9, color='tab:red',\n","                label='Animal')\n","plt.bar(6, target_geolocation_segments[4], alpha=0.9, color='tab:blue',\n","                label='Human')\n","plt.title('Target type distribution \\n')\n","plt.ylim(top=6500)\n","plt.ylabel('No. of segments')\n","plt.xlabel('\\n Target Type, Geolocation ID ')\n","\n","for index, value in enumerate(target_geolocation_segments): \n","    label = format(value, ',')\n","    plt.annotate(label, xy=(index-0.2 , value+90), color='black')\n","plt.legend()\n","plt.show()\n","\n","geolocation_distribution = pd.concat(\n","    [pd.crosstab([training_set.geolocation_id,training_set.snr_type],\n","                 training_set.target_type, margins=True, margins_name=\"Total\"),\n","     pd.crosstab([training_set.geolocation_id,training_set.snr_type], \n","                 training_set.target_type, margins=True, normalize=0, \n","                 margins_name=\"Total\").round(2)], axis=1\n","                 )\n","geolocation_distribution.columns = [\n","                                    'Animal', 'Human', 'Row Total',\n","                                    'Animal/Row Total','Human/Row Total'\n","                                    ]\n","geolocation_distribution.reset_index(inplace=True)\n","geolocation_distribution"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fBwCoSH4JGiv","colab_type":"text"},"source":["The same distribution can be presented from a different angle:"]},{"cell_type":"code","metadata":{"id":"Aw-3W_CTIM-e","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599162,"user_tz":-180,"elapsed":24994,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["geolocation_distribution = pd.concat(\n","    [pd.crosstab([training_set.target_type, training_set.snr_type],\n","    training_set.geolocation_id, margins=True, margins_name=\"Total\"), \n","    pd.crosstab([training_set.target_type, training_set.snr_type], \n","                training_set.geolocation_id, margins=True, normalize=0,\n","                margins_name=\"Total\").round(2)], axis=1\n","                )\n","geolocation_distribution.columns = [\n","                                    '1', '2', '3', '4', 'Row_Total',\n","                                    'Ratio 1', 'Ratio 2', 'Ratio 3',\n","                                    'Ratio 4',\n","                                    ]\n","geolocation_distribution"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MwG8dNDt_nPq","colab_type":"text"},"source":["##### **Analysis without geolocation_id 2 and 3**\n","One can see that geolocation 3 is very different from other geolocations and cause for imbalance in the training set.   \n","Also, notice that geolocations 2 and 3 have only Animals segments.   \n","Below, a plot of the same bar chart without geolocations 2 and 3.   "]},{"cell_type":"code","metadata":{"id":"NhFK6ehtBIS-","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599164,"user_tz":-180,"elapsed":24993,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["target_geolocation_1_and_4_segments = target_geolocation_segments.drop(\n","    labels=[('animal', '2'),('animal', '3')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rP2vp92PAEYP","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599165,"user_tz":-180,"elapsed":24969,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["print(\"Training set\")\n","\n","color_list=['tab:red']*2+['tab:blue']*2\n","target_geolocation_1_and_4_segments.plot(kind='bar', color = color_list,\n","                                 label='_nolegend_')\n","plt.title('Target type distribution \\n')\n","plt.ylim(top=600)\n","plt.ylabel('No. of segments')\n","plt.xlabel('\\n Target Type, Geolocation ID ')\n","\n","for index, value in enumerate(target_geolocation_1_and_4_segments):\n","  label = format(value, ',')\n","  plt.annotate(label, xy=(index-0.15, value+10), color='black')\n","\n","plt.bar(0, target_geolocation_1_and_4_segments[0], width=0.01, alpha=1, \n","        color='tab:red', label='Animal')\n","plt.bar(2, target_geolocation_1_and_4_segments[2], width=0.01, alpha=1, \n","        color='tab:blue', label='Human')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1gDI9DbBSCH","colab_type":"text"},"source":["Excluding geolocations 2 and 3 reveals a more balanced distribution of the target types."]},{"cell_type":"code","metadata":{"id":"tkYQ0vi9nL1m","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599170,"user_tz":-180,"elapsed":24952,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["target_geolocation_segments_count_and_ratio_1_and_4 = pd.DataFrame(data=[target_geolocation_1_and_4_segments,\n","                                                                 ratio(target_geolocation_1_and_4_segments)])\n","target_geolocation_segments_count_and_ratio_1_and_4.set_index([['count segments', 'ratio']], inplace=True)\n","target_geolocation_segments_count_and_ratio_1_and_4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cv-ISiro-XUn","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599171,"user_tz":-180,"elapsed":24934,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Bar chart - compares number of segments and tracks by snr type\n","# target type and geolocation id in the training set.\n","print(\"Training set\")\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax2 = fig.add_subplot(1, 2, 2) \n","fig.subplots_adjust(wspace=0.25)\n","color_list=['tab:red']*4+['tab:blue']*4\n","\n","target_geolocation_id_1_and_4_hsnr_lsnr.plot(kind='bar', figsize=(20,6), \n","                                  color = color_list, label='_nolegend_',\n","                                  ax=ax1)\n","ax1.set_title(\"No. of segments by target type \\n\")\n","ax1.set_ylabel('No. of segments', labelpad =15)\n","ax1.set_xlabel('Target Type,  Geolocation ID, SNR type')\n","ax1.bar(0, target_geolocation_id_1_and_4_hsnr_lsnr[0], width=0.01, alpha=0.9, \n","        color='tab:red', label='Animal')\n","ax1.bar(2, target_geolocation_id_1_and_4_hsnr_lsnr[6], width=0.01, alpha=0.9,\n","        color='tab:blue', label='Human')\n","\n","for index, value in enumerate(target_geolocation_id_1_and_4_hsnr_lsnr):\n","  label = format(value, ',')\n","  ax1.annotate(label, xy=(index-0.15, value+7), color='black')\n","\n","\n","target_geolocation_id_1_and_4_tracks_hsnr_lsnr.plot(kind='bar', figsize=(20,6), \n","                                         color=color_list, label='_nolegend_',\n","                                         ax=ax2)\n","ax2.set_title(\"No. of tracks by SNR_type \\n\")\n","ax2.set_ylabel('No. of tracks', labelpad =15)\n","ax2.set_xlabel('Target Type, Geolocation ID, SNR type')\n","\n","ax2.set_ylim(top=110)\n","for index, value in enumerate(target_geolocation_id_1_and_4_tracks_hsnr_lsnr):\n","  label = format(value, ',')\n","  ax2.annotate(label, xy=(index-0.1, value+2), color='black')\n","\n","fig.legend()\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VQYb51HxFbyp","colab_type":"text"},"source":["# Conclusions about geolocations\n","* Geolocations 2 and 3 detected animals only.\n","* Geolocation 3 detected a lot of animals and is basically the geolocation that causes the fact that the trainng set is imbalanced on the target value\n","* Geolocation 1 and 4 are well balanced.\n","* In the test set, we don't now the geolocations the radars"]},{"cell_type":"markdown","metadata":{"id":"gJq47q9pESK6","colab_type":"text"},"source":["### **Auxiliary**\n","The auxiliary dataset is separated into 3 sets:   \n","\n","1. **Synthetic**   \n","File name: *MAFAT RADAR Challenge - Auxiliary Synthetic Set V1*      \n","This set is an augmentation of the High SNR segments from the training set and the auxiliary experiment set. The High SNR segments transformed into Low SNR by adding random \"white noise\" to each segment. Therefore, the distribution of this set is identical to the distribution of the High SNR segments in the training set. \n","     \n","2. **Background (empty) Tracks**   \n","File name: *MAFAT RADAR Challenge - Auxiliary Background(empty) Set V1*   \n","The segments in this set are signals in the same geolocation, time and direction that did not recieve the target.   \n","The target (human or animal) does not appear in these segments.   \n","These tracks can help to separate between the \"background noise\" and the target. Background segments are available only in geolocation_ids 2,3,5,6. \n","    \n","3. **Experiment geolocations (geolocation_id 5,6,7)**   \n","File name: *MAFAT RADAR Challenge - Auxiliary Experiment Set V1*     \n","This set has segments of humans from 3 different geolocations.   \n","The signals from these geolocations are not \"natural\" recordings (as opposed to the segments in the training and test set) of humans.   \n","These geolocations are used for controlled tests of the radars.      "]},{"cell_type":"markdown","metadata":{"id":"T738CawyuTjO","colab_type":"text"},"source":["#### **Auxiliary - Summary Descriptive Statistics**\n","\n","\n","*   The Auxiliary Synthetic set has segments from all geolocation_id. There are 50,883 segments from 3,249 tracks.    \n","These equal to the number of segments and tracks of High SNR in the Training and Experiment data sets.   \n","The snr_type value is labeled \"SynthSNR\".\n","*   The Auxiliary Background set has segments from 4 geolocation_id ([2, 3] - only animals, [5, 6] - only humans). There are 31,128 segments from 3,064 tracks.   \n","The target_type is labeled \"empty\".\n","*   The Auxiliary Experiment set has segments from 3 geolocation_id (5, 6, 7), all segments of the same target (\"human\"). There are 49,071 segments from 3,006 tracks. "]},{"cell_type":"code","metadata":{"id":"6KJohHj3085o","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599174,"user_tz":-180,"elapsed":24932,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["synthetic_path = 'MAFAT RADAR Challenge - Auxiliary Synthetic Set V2'\n","background_path = 'MAFAT RADAR Challenge - Auxiliary Background(empty) Set V1'\n","experiment_path = 'MAFAT RADAR Challenge - Auxiliary Experiment Set V2'\n","\n","synthetic_set = load_csv_metadata(synthetic_path)\n","background_set = load_csv_metadata(background_path)\n","experiment_set = load_csv_metadata(experiment_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hK7uHahA2KH4","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599176,"user_tz":-180,"elapsed":24914,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["print(f\"The Synthetic set shape is: {synthetic_set.shape}\")\n","print(f\"The Background set shape is: {background_set.shape}\")\n","print(f\"The Experiment geolocations set shape is: {experiment_set.shape}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6BJ-79Uj3FQx","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599179,"user_tz":-180,"elapsed":24899,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["for df in [synthetic_set, background_set, experiment_set]:\n","  tracks_hsnr_and_lsnr = sum(df[['track_id', 'snr_type']].\n","                            groupby('track_id', as_index=False)\n","                            ['snr_type'].nunique()==2)\n","\n","  tracks_one_snr = sum(df[['track_id', 'snr_type']].\n","                      groupby('track_id', as_index=False)\n","                      ['snr_type'].nunique()==1)\n","\n","  total_count_of_tracks = df.groupby(['track_id', 'snr_type'], \n","                                              as_index=False).count()['track_id'].count()\n","  \n","  df.name =[x for x in globals() if globals()[x] is df][0]\n","  print(f'Tracks count in {df.name}')\n","  print(f'Number of tracks that are High SNR and Low SNR: {tracks_hsnr_and_lsnr:,}')\n","  print(f'Number of tracks that are High SNR or Low SNR: {tracks_one_snr:,}')\n","  print(f'Number of total counted tracks (grouped by snr_type and track_id): {total_count_of_tracks:,} \\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Z7ofSTtaZ4g","colab_type":"text"},"source":["#### **Relation between Auxiliary and Training data sets**\n","Connecting between the segments in the Synthetic and Background data sets to the training set \"original\" segments   \n","can be done by using the segment_id.   \n","The background's segments have segment_id with 1,000,000 added to the original segment_id in the   \n","training set or the auxiliary experiment set, and the synthetic's segments have segment_id   \n","with 2,000,000 added to the original segment_id in the training set or the auxiliary experiment set.    \n","For example:   \n","segment_id in the training set/auxiliary experiment set of an High SNR segment = 123   \n","segment_id of the background segment = 1,000,123   \n","segment_id of the synthetic segment = 2,000,123  \n"]},{"cell_type":"markdown","metadata":{"id":"OjiA6t6exvVA","colab_type":"text"},"source":["# Spectogram generator"]},{"cell_type":"code","metadata":{"id":"ffVcBomf_911","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599181,"user_tz":-180,"elapsed":24898,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["import pickle\n","from matplotlib.colors import LinearSegmentedColormap"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q1mhL_kFCtj_","colab_type":"text"},"source":["### Load data"]},{"cell_type":"code","metadata":{"id":"ymWqEIkOxz4I","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599183,"user_tz":-180,"elapsed":24897,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def load_pkl_data(file_path):\n","  \"\"\"\n","  Reads pickle file as a python dictionary (only Signal data).\n","\n","  Arguments:\n","    file_path -- {str} -- path to pickle iq_matrix file\n","\n","  Returns:\n","    Python dictionary\n","  \"\"\"\n","  path = os.path.join(mount_path, competition_path, file_path + '.pkl')\n","  with open(path, 'rb') as data:\n","    output = pickle.load(data)\n","  return output\n","\n","\n","def load_data(file_path):\n","  \"\"\"\n","  Reads all data files (metadata and signal matrix data) as python dictionary,\n","  the pkl and csv files must have the same file name.\n","\n","  Arguments:\n","  file_path -- {str} -- path to the iq_matrix file and metadata file\n","\n","  Returns:\n","  Python dictionary\n","  \"\"\"\n","  pkl = load_pkl_data(file_path)\n","  meta = load_csv_metadata(file_path)\n","  data_dictionary = {**meta, **pkl}\n","\n","  for key in data_dictionary.keys():\n","    data_dictionary[key] = np.array(data_dictionary[key])\n","\n","  return data_dictionary"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CYHWhAMYCyMP","colab_type":"text"},"source":["### Processing functions\n","\n","the functions below are taken from the `plotting spectogram` file. there is a slight change between the way it is processed to plot to the process that happens in the base line.\n","\n","**calculate spectogram** - in the baseline they used `normalization` and `max_value_on_doppler`. in this implementation there is trasformation that makes sure the minimum value of the spectogram is the median. we should still investigate more why it was processed in this way in the given baseline"]},{"cell_type":"code","metadata":{"id":"e-3Pw1Y_-zk9","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599185,"user_tz":-180,"elapsed":24897,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def hann(iq, window=None):\n","  \"\"\"\n","  Hann smoothing of 'iq_sweep_burst'.\n","\n","  Arguments:\n","    iq -- {ndarray} -- 'iq_sweep_burst' array\n","    window -- Range of Hann window indices (Default=None)\n","      If None the whole column is taken\n","\n","  Returns:\n","      Regularized iq shaped as (window[1] - window[0] - 2, iq.shape[1])\n","  \"\"\"\n","  if window is None:\n","      window = [0, len(iq)]\n","\n","  N = window[1] - window[0] - 1\n","  n = np.arange(window[0], window[1])\n","  n = n.reshape(len(n), 1)\n","  hannCol = 0.5 * (1 - np.cos(2 * np.pi * (n / N)))\n","  return (hannCol * iq[window[0]:window[1]])[1:-1]\n","\n","# Functions for preprocessing and preprocess function\n","def fft(iq, axis=0):\n","  \"\"\"\n","  Computes the log of discrete Fourier Transform (DFT).\n","     \n","  Arguments:\n","    iq_burst -- {ndarray} -- 'iq_sweep_burst' array\n","    axis -- {int} -- axis to perform fft in (Default = 0)\n","\n","  Returns:\n","    log of DFT on iq_burst array\n","  \"\"\"\n","  iq = np.log(np.abs(np.fft.fft(hann(iq), axis=axis)))\n","  return iq\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4jsWMg6A23i","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599187,"user_tz":-180,"elapsed":24896,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def calculate_spectrogram(iq_burst, axis=0, flip=True):\n","  \"\"\"\n","  Calculates spectrogram of 'iq_sweep_burst'.\n","\n","  Arguments:\n","    iq_burst -- {ndarray} -- 'iq_sweep_burst' array\n","    axis -- {int} -- axis to perform DFT in (Default = 0)\n","  \n","  Returns:\n","    Transformed iq_burst array\n","  \"\"\"\n","  iq = fft(iq_burst)\n","  iq = np.maximum(np.median(iq) - 1, iq)\n","  if flip:\n","    iq = np.flip(iq, axis=0)\n","\n","  return iq"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lvKhE0jDJOv","colab_type":"text"},"source":["### Functions to plot the spectogram"]},{"cell_type":"code","metadata":{"id":"hWw3wGxY-3be","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599206,"user_tz":-180,"elapsed":24912,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def plot_spectrogram(iq_burst, doppler_burst, color_map_name='parula',\n","                    color_map_path=None, save_path=None, flip=True, return_spec=False):\n","  \"\"\"\n","  Plots spectrogram of 'iq_sweep_burst'.\n","\n","  Arguments:\n","    iq_burst -- {ndarray} -- 'iq_sweep_burst' array\n","    doppler_burst -- {ndarray} -- 'doppler_burst' array (center of mass)\n","      if is 0 (or zero array) then not plotted\n","    color_map_name -- {str}  -- name of color map to be used (Default = 'parula')\n","      if 'parula' is set then color_map_path must be provided\n","    color_map_path -- {str} -- path to color_map file (Default=None)\n","      if None then default color map is used\n","    save_path -- {str} -- path to save image (Default = None)\n","      if None then saving is not performed\n","    flip -- {bool} -- flip the spectrogram to match Matlab spectrogram (Default = True)\n","    return_spec -- {bool} -- if True, returns spectrogram data and skips plotting and saving\n","\n","  Returns:\n","    Spectrogram data if return_spec is True\n","  \"\"\"\n","  if color_map_path is not None:\n","      cm_data = np.load(color_map_path)\n","      color_map = LinearSegmentedColormap.from_list(color_map_name, cm_data)\n","  elif color_map_name == 'parula':\n","      print(\"Error: when 'parula' color map is used, color_map_path should be provided.\")\n","      print(\"Switching color map to 'viridis'.\")\n","      color_map = None\n","  else:\n","      color_map = plt.get_cmap(color_map_name)\n","\n","  iq = calculate_spectrogram(iq_burst, flip=flip)\n","  \n","  if return_spec:\n","      return iq\n","\n","  if doppler_burst is not None:\n","      pixel_shift = 0.5\n","      if flip:\n","          plt.plot(pixel_shift + np.arange(len(doppler_burst)),\n","                    pixel_shift + (len(iq) - doppler_burst), '.w')\n","      else:\n","          plt.plot(pixel_shift + np.arange(len(doppler_burst)), pixel_shift + doppler_burst, '.w')\n","\n","  plt.imshow(iq, cmap=color_map)\n","  plt.show()\n","  if save_path is not None:\n","      plt.imsave(save_path, iq, cmap=color_map)\n","\n","  plt.clf()\n","\n","\n","def get_track_id(data, segment_id):\n","  \"\"\"\n","  Get track id from segment id.\n","\n","  Arguments:\n","    data -- {dictionary} -- python dictionary of python numpy arrays\n","    segment_id -- {int} -- segment id of a track\n","\n","  Returns:\n","    Track id\n","  \"\"\"\n","  segment_index = np.where(data['segment_id'] == segment_id)\n","  return data['track_id'][segment_index][0]\n","\n","\n","def has_single_snr_type(data, id, is_segment):\n","  \"\"\"\n","  Check if a track has a single SNR type or both High and Low SNR.\n","\n","  Arguments:\n","    data -- {dictionary} -- python dictionary of python numpy arrays\n","    id -- {int} -- segment or track id, based on is_segment\n","    is_segment -- {bool} -- If true then id is segment, otherwise id is track\n","\n","  Returns:\n","    True if track has a High or Low SNR but not both\n","  \"\"\"\n","  if is_segment:\n","    id = get_track_id(data, id)\n","  return np.all(data['snr_type'][np.where(data['track_id'] == id)] == data['snr_type']\\\n","                [np.where(data['track_id'] == id)][0], axis = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YbK0cs_--6hv","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599208,"user_tz":-180,"elapsed":24913,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["#@title\n","spectrogram_cmap = np.array([[2.422e-01, 1.504e-01, 6.603e-01],\n","       [2.444e-01, 1.534e-01, 6.728e-01],\n","       [2.464e-01, 1.569e-01, 6.847e-01],\n","       [2.484e-01, 1.607e-01, 6.961e-01],\n","       [2.503e-01, 1.648e-01, 7.071e-01],\n","       [2.522e-01, 1.689e-01, 7.179e-01],\n","       [2.540e-01, 1.732e-01, 7.286e-01],\n","       [2.558e-01, 1.773e-01, 7.393e-01],\n","       [2.576e-01, 1.814e-01, 7.501e-01],\n","       [2.594e-01, 1.854e-01, 7.610e-01],\n","       [2.611e-01, 1.893e-01, 7.719e-01],\n","       [2.628e-01, 1.932e-01, 7.828e-01],\n","       [2.645e-01, 1.972e-01, 7.937e-01],\n","       [2.661e-01, 2.011e-01, 8.043e-01],\n","       [2.676e-01, 2.052e-01, 8.148e-01],\n","       [2.691e-01, 2.094e-01, 8.249e-01],\n","       [2.704e-01, 2.138e-01, 8.346e-01],\n","       [2.717e-01, 2.184e-01, 8.439e-01],\n","       [2.729e-01, 2.231e-01, 8.528e-01],\n","       [2.740e-01, 2.280e-01, 8.612e-01],\n","       [2.749e-01, 2.330e-01, 8.692e-01],\n","       [2.758e-01, 2.382e-01, 8.767e-01],\n","       [2.766e-01, 2.435e-01, 8.840e-01],\n","       [2.774e-01, 2.489e-01, 8.908e-01],\n","       [2.781e-01, 2.543e-01, 8.973e-01],\n","       [2.788e-01, 2.598e-01, 9.035e-01],\n","       [2.794e-01, 2.653e-01, 9.094e-01],\n","       [2.798e-01, 2.708e-01, 9.150e-01],\n","       [2.802e-01, 2.764e-01, 9.204e-01],\n","       [2.806e-01, 2.819e-01, 9.255e-01],\n","       [2.809e-01, 2.875e-01, 9.305e-01],\n","       [2.811e-01, 2.930e-01, 9.352e-01],\n","       [2.813e-01, 2.985e-01, 9.397e-01],\n","       [2.814e-01, 3.040e-01, 9.441e-01],\n","       [2.814e-01, 3.095e-01, 9.483e-01],\n","       [2.813e-01, 3.150e-01, 9.524e-01],\n","       [2.811e-01, 3.204e-01, 9.563e-01],\n","       [2.809e-01, 3.259e-01, 9.600e-01],\n","       [2.807e-01, 3.313e-01, 9.636e-01],\n","       [2.803e-01, 3.367e-01, 9.670e-01],\n","       [2.798e-01, 3.421e-01, 9.702e-01],\n","       [2.791e-01, 3.475e-01, 9.733e-01],\n","       [2.784e-01, 3.529e-01, 9.763e-01],\n","       [2.776e-01, 3.583e-01, 9.791e-01],\n","       [2.766e-01, 3.638e-01, 9.817e-01],\n","       [2.754e-01, 3.693e-01, 9.840e-01],\n","       [2.741e-01, 3.748e-01, 9.862e-01],\n","       [2.726e-01, 3.804e-01, 9.881e-01],\n","       [2.710e-01, 3.860e-01, 9.898e-01],\n","       [2.691e-01, 3.916e-01, 9.912e-01],\n","       [2.670e-01, 3.973e-01, 9.924e-01],\n","       [2.647e-01, 4.030e-01, 9.935e-01],\n","       [2.621e-01, 4.088e-01, 9.946e-01],\n","       [2.591e-01, 4.145e-01, 9.955e-01],\n","       [2.556e-01, 4.203e-01, 9.965e-01],\n","       [2.517e-01, 4.261e-01, 9.974e-01],\n","       [2.473e-01, 4.319e-01, 9.983e-01],\n","       [2.424e-01, 4.378e-01, 9.991e-01],\n","       [2.369e-01, 4.437e-01, 9.996e-01],\n","       [2.311e-01, 4.497e-01, 9.995e-01],\n","       [2.250e-01, 4.559e-01, 9.985e-01],\n","       [2.189e-01, 4.620e-01, 9.968e-01],\n","       [2.128e-01, 4.682e-01, 9.948e-01],\n","       [2.066e-01, 4.743e-01, 9.926e-01],\n","       [2.006e-01, 4.803e-01, 9.906e-01],\n","       [1.950e-01, 4.861e-01, 9.887e-01],\n","       [1.903e-01, 4.919e-01, 9.867e-01],\n","       [1.869e-01, 4.975e-01, 9.844e-01],\n","       [1.847e-01, 5.030e-01, 9.819e-01],\n","       [1.831e-01, 5.084e-01, 9.793e-01],\n","       [1.818e-01, 5.138e-01, 9.766e-01],\n","       [1.806e-01, 5.191e-01, 9.738e-01],\n","       [1.795e-01, 5.244e-01, 9.709e-01],\n","       [1.785e-01, 5.296e-01, 9.677e-01],\n","       [1.778e-01, 5.349e-01, 9.641e-01],\n","       [1.773e-01, 5.401e-01, 9.602e-01],\n","       [1.768e-01, 5.452e-01, 9.560e-01],\n","       [1.764e-01, 5.504e-01, 9.516e-01],\n","       [1.755e-01, 5.554e-01, 9.473e-01],\n","       [1.740e-01, 5.605e-01, 9.432e-01],\n","       [1.716e-01, 5.655e-01, 9.393e-01],\n","       [1.686e-01, 5.705e-01, 9.357e-01],\n","       [1.649e-01, 5.755e-01, 9.323e-01],\n","       [1.610e-01, 5.805e-01, 9.289e-01],\n","       [1.573e-01, 5.854e-01, 9.254e-01],\n","       [1.540e-01, 5.902e-01, 9.218e-01],\n","       [1.513e-01, 5.950e-01, 9.182e-01],\n","       [1.492e-01, 5.997e-01, 9.147e-01],\n","       [1.475e-01, 6.043e-01, 9.113e-01],\n","       [1.461e-01, 6.089e-01, 9.080e-01],\n","       [1.446e-01, 6.135e-01, 9.050e-01],\n","       [1.429e-01, 6.180e-01, 9.022e-01],\n","       [1.408e-01, 6.226e-01, 8.998e-01],\n","       [1.383e-01, 6.272e-01, 8.975e-01],\n","       [1.354e-01, 6.317e-01, 8.953e-01],\n","       [1.321e-01, 6.363e-01, 8.932e-01],\n","       [1.288e-01, 6.408e-01, 8.910e-01],\n","       [1.253e-01, 6.453e-01, 8.887e-01],\n","       [1.219e-01, 6.497e-01, 8.862e-01],\n","       [1.185e-01, 6.541e-01, 8.834e-01],\n","       [1.152e-01, 6.584e-01, 8.804e-01],\n","       [1.119e-01, 6.627e-01, 8.770e-01],\n","       [1.085e-01, 6.669e-01, 8.734e-01],\n","       [1.048e-01, 6.710e-01, 8.695e-01],\n","       [1.009e-01, 6.750e-01, 8.653e-01],\n","       [9.640e-02, 6.789e-01, 8.609e-01],\n","       [9.140e-02, 6.828e-01, 8.562e-01],\n","       [8.550e-02, 6.865e-01, 8.513e-01],\n","       [7.890e-02, 6.902e-01, 8.462e-01],\n","       [7.130e-02, 6.938e-01, 8.409e-01],\n","       [6.280e-02, 6.972e-01, 8.355e-01],\n","       [5.350e-02, 7.006e-01, 8.299e-01],\n","       [4.330e-02, 7.039e-01, 8.242e-01],\n","       [3.280e-02, 7.071e-01, 8.183e-01],\n","       [2.340e-02, 7.103e-01, 8.124e-01],\n","       [1.550e-02, 7.133e-01, 8.064e-01],\n","       [9.100e-03, 7.163e-01, 8.003e-01],\n","       [4.600e-03, 7.192e-01, 7.941e-01],\n","       [1.900e-03, 7.220e-01, 7.878e-01],\n","       [9.000e-04, 7.248e-01, 7.815e-01],\n","       [1.800e-03, 7.275e-01, 7.752e-01],\n","       [4.600e-03, 7.301e-01, 7.688e-01],\n","       [9.400e-03, 7.327e-01, 7.623e-01],\n","       [1.620e-02, 7.352e-01, 7.558e-01],\n","       [2.530e-02, 7.376e-01, 7.492e-01],\n","       [3.690e-02, 7.400e-01, 7.426e-01],\n","       [5.040e-02, 7.423e-01, 7.359e-01],\n","       [6.380e-02, 7.446e-01, 7.292e-01],\n","       [7.700e-02, 7.468e-01, 7.224e-01],\n","       [8.990e-02, 7.489e-01, 7.156e-01],\n","       [1.023e-01, 7.510e-01, 7.088e-01],\n","       [1.141e-01, 7.531e-01, 7.019e-01],\n","       [1.252e-01, 7.552e-01, 6.950e-01],\n","       [1.354e-01, 7.572e-01, 6.881e-01],\n","       [1.448e-01, 7.593e-01, 6.812e-01],\n","       [1.532e-01, 7.614e-01, 6.741e-01],\n","       [1.609e-01, 7.635e-01, 6.671e-01],\n","       [1.678e-01, 7.656e-01, 6.599e-01],\n","       [1.741e-01, 7.678e-01, 6.527e-01],\n","       [1.799e-01, 7.699e-01, 6.454e-01],\n","       [1.853e-01, 7.721e-01, 6.379e-01],\n","       [1.905e-01, 7.743e-01, 6.303e-01],\n","       [1.954e-01, 7.765e-01, 6.225e-01],\n","       [2.003e-01, 7.787e-01, 6.146e-01],\n","       [2.061e-01, 7.808e-01, 6.065e-01],\n","       [2.118e-01, 7.828e-01, 5.983e-01],\n","       [2.178e-01, 7.849e-01, 5.899e-01],\n","       [2.244e-01, 7.869e-01, 5.813e-01],\n","       [2.318e-01, 7.887e-01, 5.725e-01],\n","       [2.401e-01, 7.905e-01, 5.636e-01],\n","       [2.491e-01, 7.922e-01, 5.546e-01],\n","       [2.589e-01, 7.937e-01, 5.454e-01],\n","       [2.695e-01, 7.951e-01, 5.360e-01],\n","       [2.809e-01, 7.964e-01, 5.266e-01],\n","       [2.929e-01, 7.975e-01, 5.170e-01],\n","       [3.052e-01, 7.985e-01, 5.074e-01],\n","       [3.176e-01, 7.994e-01, 4.975e-01],\n","       [3.301e-01, 8.002e-01, 4.876e-01],\n","       [3.424e-01, 8.009e-01, 4.774e-01],\n","       [3.548e-01, 8.016e-01, 4.669e-01],\n","       [3.671e-01, 8.021e-01, 4.563e-01],\n","       [3.795e-01, 8.026e-01, 4.454e-01],\n","       [3.921e-01, 8.029e-01, 4.344e-01],\n","       [4.050e-01, 8.031e-01, 4.233e-01],\n","       [4.184e-01, 8.030e-01, 4.122e-01],\n","       [4.322e-01, 8.028e-01, 4.013e-01],\n","       [4.463e-01, 8.024e-01, 3.904e-01],\n","       [4.608e-01, 8.018e-01, 3.797e-01],\n","       [4.753e-01, 8.011e-01, 3.691e-01],\n","       [4.899e-01, 8.002e-01, 3.586e-01],\n","       [5.044e-01, 7.993e-01, 3.480e-01],\n","       [5.187e-01, 7.982e-01, 3.374e-01],\n","       [5.329e-01, 7.970e-01, 3.267e-01],\n","       [5.470e-01, 7.957e-01, 3.159e-01],\n","       [5.609e-01, 7.943e-01, 3.050e-01],\n","       [5.748e-01, 7.929e-01, 2.941e-01],\n","       [5.886e-01, 7.913e-01, 2.833e-01],\n","       [6.024e-01, 7.896e-01, 2.726e-01],\n","       [6.161e-01, 7.878e-01, 2.622e-01],\n","       [6.297e-01, 7.859e-01, 2.521e-01],\n","       [6.433e-01, 7.839e-01, 2.423e-01],\n","       [6.567e-01, 7.818e-01, 2.329e-01],\n","       [6.701e-01, 7.796e-01, 2.239e-01],\n","       [6.833e-01, 7.773e-01, 2.155e-01],\n","       [6.963e-01, 7.750e-01, 2.075e-01],\n","       [7.091e-01, 7.727e-01, 1.998e-01],\n","       [7.218e-01, 7.703e-01, 1.924e-01],\n","       [7.344e-01, 7.679e-01, 1.852e-01],\n","       [7.468e-01, 7.654e-01, 1.782e-01],\n","       [7.590e-01, 7.629e-01, 1.717e-01],\n","       [7.710e-01, 7.604e-01, 1.658e-01],\n","       [7.829e-01, 7.579e-01, 1.608e-01],\n","       [7.945e-01, 7.554e-01, 1.570e-01],\n","       [8.060e-01, 7.529e-01, 1.546e-01],\n","       [8.172e-01, 7.505e-01, 1.535e-01],\n","       [8.281e-01, 7.481e-01, 1.536e-01],\n","       [8.389e-01, 7.457e-01, 1.546e-01],\n","       [8.495e-01, 7.435e-01, 1.564e-01],\n","       [8.600e-01, 7.413e-01, 1.587e-01],\n","       [8.703e-01, 7.392e-01, 1.615e-01],\n","       [8.804e-01, 7.372e-01, 1.650e-01],\n","       [8.903e-01, 7.353e-01, 1.695e-01],\n","       [9.000e-01, 7.336e-01, 1.749e-01],\n","       [9.093e-01, 7.321e-01, 1.815e-01],\n","       [9.184e-01, 7.308e-01, 1.890e-01],\n","       [9.272e-01, 7.298e-01, 1.973e-01],\n","       [9.357e-01, 7.290e-01, 2.061e-01],\n","       [9.440e-01, 7.285e-01, 2.151e-01],\n","       [9.523e-01, 7.284e-01, 2.237e-01],\n","       [9.606e-01, 7.285e-01, 2.312e-01],\n","       [9.689e-01, 7.292e-01, 2.373e-01],\n","       [9.770e-01, 7.304e-01, 2.418e-01],\n","       [9.842e-01, 7.330e-01, 2.446e-01],\n","       [9.900e-01, 7.365e-01, 2.429e-01],\n","       [9.946e-01, 7.407e-01, 2.394e-01],\n","       [9.966e-01, 7.458e-01, 2.351e-01],\n","       [9.971e-01, 7.513e-01, 2.309e-01],\n","       [9.972e-01, 7.569e-01, 2.267e-01],\n","       [9.971e-01, 7.626e-01, 2.224e-01],\n","       [9.969e-01, 7.683e-01, 2.181e-01],\n","       [9.966e-01, 7.740e-01, 2.138e-01],\n","       [9.962e-01, 7.798e-01, 2.095e-01],\n","       [9.957e-01, 7.856e-01, 2.053e-01],\n","       [9.949e-01, 7.915e-01, 2.012e-01],\n","       [9.938e-01, 7.974e-01, 1.974e-01],\n","       [9.923e-01, 8.034e-01, 1.939e-01],\n","       [9.906e-01, 8.095e-01, 1.906e-01],\n","       [9.885e-01, 8.156e-01, 1.875e-01],\n","       [9.861e-01, 8.218e-01, 1.846e-01],\n","       [9.835e-01, 8.280e-01, 1.817e-01],\n","       [9.807e-01, 8.342e-01, 1.787e-01],\n","       [9.778e-01, 8.404e-01, 1.757e-01],\n","       [9.748e-01, 8.467e-01, 1.726e-01],\n","       [9.720e-01, 8.529e-01, 1.695e-01],\n","       [9.694e-01, 8.591e-01, 1.665e-01],\n","       [9.671e-01, 8.654e-01, 1.636e-01],\n","       [9.651e-01, 8.716e-01, 1.608e-01],\n","       [9.634e-01, 8.778e-01, 1.582e-01],\n","       [9.619e-01, 8.840e-01, 1.557e-01],\n","       [9.608e-01, 8.902e-01, 1.532e-01],\n","       [9.601e-01, 8.963e-01, 1.507e-01],\n","       [9.596e-01, 9.023e-01, 1.480e-01],\n","       [9.595e-01, 9.084e-01, 1.450e-01],\n","       [9.597e-01, 9.143e-01, 1.418e-01],\n","       [9.601e-01, 9.203e-01, 1.382e-01],\n","       [9.608e-01, 9.262e-01, 1.344e-01],\n","       [9.618e-01, 9.320e-01, 1.304e-01],\n","       [9.629e-01, 9.379e-01, 1.261e-01],\n","       [9.642e-01, 9.437e-01, 1.216e-01],\n","       [9.657e-01, 9.494e-01, 1.168e-01],\n","       [9.674e-01, 9.552e-01, 1.116e-01],\n","       [9.692e-01, 9.609e-01, 1.061e-01],\n","       [9.711e-01, 9.667e-01, 1.001e-01],\n","       [9.730e-01, 9.724e-01, 9.380e-02],\n","       [9.749e-01, 9.782e-01, 8.720e-02],\n","       [9.769e-01, 9.839e-01, 8.050e-02]])\n","\n","np.save('/content/cmap.npy', spectrogram_cmap)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qx7RQJJh-7E0","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599210,"user_tz":-180,"elapsed":24911,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def spectrogram(data, segment_id=None, plot_track=False, track_id=None, snr_plot='both',\n","                color_map_name='parula', color_map_path=None, save_path=None, flip=True,\n","                return_spec=False):\n","  \"\"\"\n","  Plots spectrogram of a track or of a single segment I/Q matrix ('iq_sweep_burst').\n","  If segment_id is passed than plots spectrogram for the specific segment,\n","  unless plot_track=='True' and than plots the entire track of the segment.\n","  If track_id is passed than plots spectrogram for the entire track.\n","  In case that the Track has two SNR Types asks the user to choose HighSNR or LowSNR or ignore.\n","  If color map is 'parula' must pass color_map_path.        \n","\n","  Arguments:\n","    data -- {dictionary} -- python dictionary of python numpy arrays\n","    segment_id -- {int} -- the segment_id number of the wanted segment\n","    track_id -- {int} -- the segment_id number of the wanted segment\n","    snr_plot -- {str} -- If track has both high and low SNR signals which SNR to plot (Default = 'both')\n","      The valid values are: 'HighSNR', 'LowSNR' or 'both'\n","    iq_burst -- {ndarray} -- 'iq_sweep_burst' array\n","    doppler_burst -- {ndarray} -- 'doppler_burst' array (center of mass)\n","      if is 0 (or zero array) then not plotted\n","    color_map_name -- {str}  -- name of color map to be used (Default = 'parula')\n","      if 'parula' is set then color_map_path must be provided\n","    color_map_path -- {str} -- path to color_map file (Default=None)\n","      if None then default color map is used\n","    save_path -- {str} -- path to save image (Default = None)\n","      if None then saving is not performed\n","    flip -- {bool} -- flip the spectrogram to match Matlab spectrogram (Default = True)\n","    return_spec -- {bool} -- if True, returns spectrogram data and skips plotting and saving\n","  \n","  Returns:\n","    Spectrogram data if return_spec is True\n","  \"\"\"\n","  if (segment_id == None) and (track_id == None):\n","    raise ValueError(\"You must pass segment id or track id\")\n","  elif (segment_id != None) and (track_id != None):\n","    raise ValueError(\"You must pass segment id or track id, you can't pass both.\",\n","    \"\\nIf you want to plot the entire track of a segment by passig only the segment_id than set 'plot_track'=True\")\n","  elif (segment_id != None) and (track_id == None):\n","    segment_index = np.where(data['segment_id'] == segment_id)\n","    if not plot_track:\n","      iq_matrix = data['iq_sweep_burst'][segment_index]\n","      iq_matrix = iq_matrix.reshape(iq_matrix.shape[1], -1)\n","      doppler_vector = data['doppler_burst'][segment_index]\n","      doppler_vector = doppler_vector.reshape(doppler_vector.shape[1])\n","      return doppler_vector, plot_spectrogram(iq_burst=iq_matrix, doppler_burst=doppler_vector, color_map_name=color_map_name,\n","                      color_map_path=color_map_path, save_path=save_path, flip=flip, return_spec=return_spec)\n","    else:\n","        '''plot_track=True than plots all track by segment_id'''\n","        track_id = data['track_id'][segment_index]\n","        return spectrogram(data, segment_id=None, plot_track=False, track_id=track_id,\n","                    snr_plot=snr_plot, color_map_name=color_map_name, \n","                    color_map_path=color_map_path, save_path=save_path, flip=flip, \n","                    return_spec=return_spec)\n","  else:\n","    ''' track_id is passed, plotting the entire track '''\n","    track_indices = np.where(data['track_id'] == track_id)\n","    iq_list = []\n","    dopller_list = []\n","\n","    if (snr_plot != 'both') and (not has_single_snr_type(data, track_id, False)):\n","      # if we want only single snr plot, but this specific track have several, picl the chosen one\n","      track_indices = np.where((data['track_id'] == track_id) & (data['snr_type'] == snr_plot))\n","    \n","    for i in track_indices:\n","        iq_list.append(data['iq_sweep_burst'][i])\n","        dopller_list.append(data['doppler_burst'][i])\n","      \n","    iq_matrix = np.concatenate(np.concatenate(iq_list, axis=1),axis=1)\n","    doppler_vector = np.concatenate(np.concatenate(dopller_list, axis=0),axis=0)\n","\n","    return doppler_vector, plot_spectrogram(iq_burst=iq_matrix, doppler_burst=doppler_vector, \n","                     color_map_name=color_map_name, color_map_path=color_map_path, \n","                     save_path=save_path, flip=flip, return_spec=return_spec)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5DLm9dO_DGI","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599212,"user_tz":-180,"elapsed":24910,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Load data\n","training_path = 'MAFAT RADAR Challenge - Training Set V1'\n","training = load_data(training_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HAiLqKedUwt9","colab_type":"text"},"source":["### Segment data study"]},{"cell_type":"code","metadata":{"id":"YAMTJTosWaH4","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599214,"user_tz":-180,"elapsed":24891,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["segments = training['iq_sweep_burst']\n","print(f\"In the training set we got {segments.shape[0]} segments.\")\n","print(f\"Each of them representing an IQ matrix of size {segments.shape[1]} * {segments.shape[2]}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QivoRX-hXa7X","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599216,"user_tz":-180,"elapsed":24875,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["segment = segments[0]\n","print(f\"Exemple of the value in one of the cell of the matrix, cell (0, 0) : {segment[0][0]} \")\n","print(f\"Type of the value : {type(segment[0][0])} \")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O72jKJJ-DRWP","colab_type":"text"},"source":["### Plot basic spectogram"]},{"cell_type":"code","metadata":{"id":"rQ5-D5bv_4EV","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599217,"user_tz":-180,"elapsed":24849,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["spectrogram(training, track_id=11, color_map_path='/content/cmap.npy');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"75PtMNGcDZLE","colab_type":"text"},"source":["### Function for presenting animal and human side by side"]},{"cell_type":"code","metadata":{"id":"jXBfwPviADhc","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599219,"user_tz":-180,"elapsed":24846,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def plot_animal_versus_human(data, num_examples=3, return_spec=True, color_map_path='/content/cmap.npy'):\n","\n","    pixel_shift = 0.5\n","    cm_data = np.load(color_map_path)\n","    color_map = LinearSegmentedColormap.from_list('parula', cm_data)\n","\n","\n","    animals_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 'animal')]))\n","    humans_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 'human')]))\n","\n","    if (not animals_list) or (not humans_list):\n","        animals_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 0)]))\n","        humans_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 1)]))\n","\n","    animals = np.random.choice(animals_list, size=num_examples)\n","    humans = np.random.choice(humans_list, size=num_examples)\n","\n","    fig, ax = plt.subplots(num_examples, 2, figsize=(15, 3*num_examples))\n","\n","    for i in range(num_examples):\n","      doppler_burst_animal, iq_animal = spectrogram(data, track_id=animals[i], return_spec=return_spec, color_map_path=color_map_path)\n","      doppler_burst_human, iq_human = spectrogram(data, track_id=humans[i], return_spec=return_spec, color_map_path=color_map_path)\n","\n","      ax[i][0].plot(pixel_shift + np.arange(len(doppler_burst_animal)), pixel_shift + (len(iq_animal) - doppler_burst_animal), '.w')\n","      ax[i][1].plot(pixel_shift + np.arange(len(doppler_burst_human)), pixel_shift + (len(iq_human) - doppler_burst_human), '.w')\n","\n","      ax[i][0].imshow(iq_animal, cmap=color_map);\n","      ax[i][1].imshow(iq_human, cmap=color_map);\n","\n","      ax[i][0].set_title(f\"animal - track id: {animals[i]}\")\n","      ax[i][1].set_title(f\"human - track id: {humans[i]}\")\n","    \n","    plt.tight_layout()\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojIZU2SCASDJ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599222,"user_tz":-180,"elapsed":24826,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["plot_animal_versus_human(training, num_examples=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yelFgOQH9AWf","colab_type":"text"},"source":["### Ploting difference between SNR type"]},{"cell_type":"code","metadata":{"id":"2BQBGIRYAUra","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599224,"user_tz":-180,"elapsed":24825,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["def plot_snr_difference(data, num_examples=3, return_spec=True, color_map_path='/content/cmap.npy'):\n","\n","    pixel_shift = 0.5\n","    cm_data = np.load(color_map_path)\n","    color_map = LinearSegmentedColormap.from_list('parula', cm_data)\n","\n","\n","    animals_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 'animal')]))\n","    humans_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 'human')]))\n","\n","    if (not animals_list) or (not humans_list):\n","        animals_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 0)]))\n","        humans_list = list(set(data[\"track_id\"][np.where(data['target_type'] == 1)]))\n","\n","    both_snr_track_animal = [track for track in animals_list if not has_single_snr_type(data, track, is_segment=False)]\n","    both_snr_track_human = [track for track in humans_list if not has_single_snr_type(data, track, is_segment=False)]\n","\n","\n","    animals = np.random.choice(both_snr_track_animal, size=num_examples)\n","    humans = np.random.choice(both_snr_track_human, size=num_examples)\n","\n","    fig, ax = plt.subplots(num_examples, 3, figsize=(15, 3*num_examples))\n","\n","    for i in range(num_examples):\n","      doppler_burst_animal_high, iq_animal_high = spectrogram(data, track_id=animals[i], return_spec=return_spec,snr_plot='HighSNR', color_map_path=color_map_path)\n","      ax[i][0].plot(pixel_shift + np.arange(len(doppler_burst_animal_high)), pixel_shift + (len(iq_animal_high) - doppler_burst_animal_high), '.w')\n","      ax[i][0].imshow(iq_animal_high, cmap=color_map);\n","      ax[i][0].set_title(f\"animal - track id: {animals[i]}, High SNR\")\n","\n","      doppler_burst_animal_low, iq_animal_low = spectrogram(data, track_id=animals[i], return_spec=return_spec,snr_plot='LowSNR', color_map_path=color_map_path)\n","      ax[i][1].plot(pixel_shift + np.arange(len(doppler_burst_animal_low)), pixel_shift + (len(iq_animal_low) - doppler_burst_animal_low), '.w')\n","      ax[i][1].imshow(iq_animal_low, cmap=color_map);\n","      ax[i][1].set_title(f\"animal - track id: {animals[i]}, Low SNR\")\n","\n","      doppler_burst_animal_both, iq_animal_both = spectrogram(data, track_id=animals[i], return_spec=return_spec,snr_plot='both', color_map_path=color_map_path)\n","      ax[i][2].plot(pixel_shift + np.arange(len(doppler_burst_animal_both)), pixel_shift + (len(iq_animal_both) - doppler_burst_animal_both), '.w')\n","      ax[i][2].imshow(iq_animal_both, cmap=color_map);\n","      ax[i][2].set_title(f\"animal - track id: {animals[i]}, both\")\n","\n","\n","    plt.tight_layout()    \n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KkAW02uc7abg","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599225,"user_tz":-180,"elapsed":24808,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["plot_snr_difference(training)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5LRnxP2x9Fk6","colab_type":"text"},"source":["### ploting examples from the auxilary datasets and from the test set"]},{"cell_type":"code","metadata":{"id":"jklFgGX89KpC","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599227,"user_tz":-180,"elapsed":24807,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Loading Auxiliary Experiment set - set has segments of humans not \"natural\" \n","experiment_auxiliary = 'MAFAT RADAR Challenge - Auxiliary Experiment Set V2'\n","experiment_auxiliary_df = load_data(experiment_auxiliary)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"so5GAovYCmxX","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599229,"user_tz":-180,"elapsed":24789,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["spectrogram(experiment_auxiliary_df, track_id=275251, color_map_path='/content/cmap.npy');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_CYKWwcFD4g","colab_type":"text"},"source":["the spectogram of the expiriment dataset looks like maybe it was already processed or any other possibility. we should investigate this result"]},{"cell_type":"code","metadata":{"id":"ks31-xTp_asF","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599231,"user_tz":-180,"elapsed":24788,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Loading Auxiliary Synthetic set - \n","#  High SNR segments transformed into Low SNR by adding random \"white noise\" to each segment\n","synthetic_auxiliary = 'MAFAT RADAR Challenge - Auxiliary Synthetic Set V2'\n","synthetic_auxiliary_df = load_data(synthetic_auxiliary)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cq-cTUqLC5uv","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599232,"user_tz":-180,"elapsed":24773,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["spectrogram(synthetic_auxiliary_df, track_id=11, color_map_path='/content/cmap.npy');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jLz8cYZAyrI","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599234,"user_tz":-180,"elapsed":24770,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["# Loading Auxiliary Background(empty) set - \n","# segments in this set are signals in the same geolocation, time and direction that did not recieve the target\n","background_auxiliary = 'MAFAT RADAR Challenge - Auxiliary Background(empty) Set V1'\n","background_auxiliary_df = load_data(background_auxiliary)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRyclxxQ-p7L","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599059599237,"user_tz":-180,"elapsed":24750,"user":{"displayName":"inbar shirizly","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64","userId":"04186382058769434872"}}},"source":["spectrogram(background_auxiliary_df, track_id=349, color_map_path='/content/cmap.npy');"],"execution_count":null,"outputs":[]}]}